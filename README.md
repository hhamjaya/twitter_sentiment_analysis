# Machine Learning Lab 2

## Project Overview

This project focuses on sentiment analysis using the **Sentiment140 dataset**, which contains over 1.6 million tweets that have been automatically annotated with sentiment labels. The goal is to develop two different machine learning models for sentiment analysis and compare their performance. The project will also involve analyzing and processing the data, building the models, and visualizing the results.

## Dataset

The **Sentiment140 dataset** is a collection of tweets labeled with their sentiment. It was created by Stanford graduate students Alec Go, Richa Bhayani, and Lei Huang. Each tweet in the dataset has a corresponding sentiment label:
- **0**: Negative sentiment
- **4**: Positive sentiment

The dataset is publicly available and consists of:
- Approximately **1,600,000** tweets.
- Automatically labeled as either positive or negative sentiment.

For this project, we will preprocess the dataset, train two different machine learning models for sentiment classification, and compare their performance.

## Project Tasks

### Task 1: Build Two Machine Learning Models for Sentiment Analysis

- We will experiment with two machine learning models, where at least one model will utilize a traditional approach (e.g., Naive Bayes, Random Forest, or SVM) and the other model will incorporate a more advanced technique (e.g., deep learning models like CNNs, RNNs, or Transformer architectures).
  
- **Traditional Approaches**: Examples include Random Forest, Na√Øve Bayes, or SVM.
- **Advanced Approaches**: Examples include CNNs, RNNs, or fine-tuned Transformers (e.g., BERT).

You are free to experiment with any model you find suitable based on research or course material.

### Task 2: Compare and Visualize the Performance of the Models

- Once both models are trained, compare their performance on a variety of metrics, such as **accuracy**, **precision**, **recall**, and **F1-score**.
- Visualize the results using appropriate graphs (e.g., confusion matrices, ROC curves, etc.) to evaluate the strengths and weaknesses of each model.

### Task 3: Write a Scientific Report

Your final report should address the following:

1. **Introduction**:  
   - What problem are you solving?  
   - Why is sentiment analysis on Twitter data important?

2. **Data Processing**:  
   - What preprocessing steps did you take with the data?  
   - How did you handle missing data, tokenization, stopwords, and text vectorization?  
   - What choices did you make regarding feature engineering?

3. **Modeling**:  
   - What models did you choose and why?  
   - How did you perform them (e.g., hyperparameter tuning, cross-validation)?  
   - Why did one model perform better than the other?  
   - What improvements could be made to the models?

4. **Conclusions**:  
   - What were the scientific bottlenecks or challenges you encountered?  
   - How did you overcome them?  
   - Which model worked better and why?


## Overall Feedback:
Very nice and great work